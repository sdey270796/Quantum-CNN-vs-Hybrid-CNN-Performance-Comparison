{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLeF5Nmdef0V"
      },
      "source": [
        "# Quantum Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D3xaWBHOIVg"
      },
      "source": [
        "This tutorial presents a simplified implementation of a [Quantum Convolutional Neural Network (QCNN)](https://www.nature.com/articles/s41567-019-0648-8), a proposed quantum counterpart to the classical convolutional neural network (CNN). The QCNN is designed to mimic the structure and function of a classical CNN while incorporating *translational invariance*, meaning it can detect certain properties regardless of where they appear in the data—similar to how classical CNNs identify features across different regions of an image.\n",
        "\n",
        "In this example, the QCNN is used to analyze and identify specific characteristics in a quantum data source, such as data coming from a quantum sensor or a complex quantum simulation on a device. The quantum data source in this case is a [cluster state](https://arxiv.org/pdf/quant-ph/0504097.pdf), a type of entangled quantum state that may contain an excitation. The QCNN is trained to detect the presence or absence of this excitation, learning to distinguish between different configurations of the cluster state.\n",
        "\n",
        "The dataset used in the original research paper was based on SPT (Symmetry-Protected Topological) phase classification, where the QCNN effectively identified different phases within quantum data. This tutorial demonstrates how QCNNs can be leveraged for such tasks, showing the potential for quantum models to recognize complex patterns in quantum-specific datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnjolLuz8o5C"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aquwcz-0aHqz",
        "vscode": {
          "languageId": "python"
        },
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.15.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_ZuLN_N8yhT"
      },
      "source": [
        "## Install TensorFlow Quantum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Pl5PW-ACO9J",
        "vscode": {
          "languageId": "python"
        },
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-quantum==0.7.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ql5PW-ACO0J",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Update package resources to account for version changes.\n",
        "import importlib, pkg_resources\n",
        "importlib.reload(pkg_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL_LvHXzPNjW"
      },
      "source": [
        "## Import TensorFlow and the Module Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QytLEAtoejW5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6331ZSsQGY3"
      },
      "source": [
        "# Build a QCNN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assemble circuits in a TensorFlow graph"
      ],
      "metadata": {
        "id": "KMGHFU4Yrksp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg85u3G--CGq"
      },
      "source": [
        "TensorFlow Quantum (TFQ) includes a variety of specialized layer classes tailored for constructing quantum circuits within the TensorFlow computation graph. These layers enable the seamless integration of quantum circuits and classical neural network components in a hybrid quantum-classical model. One of the key layers provided by TFQ is the `tfq.layers.AddCircuit` layer, which is derived from the `tf.keras.Layer` class in TensorFlow. This layer is specifically designed to modify the input batch of quantum circuits by adding another circuit to each one.\n",
        "\n",
        "The `tfq.layers.AddCircuit` layer offers flexibility in its usage by allowing you to either **prepend** or **append** the additional circuit to the input batch of circuits, depending on your modeling requirements. By doing so, you can control the placement of this additional circuit in relation to the existing circuits in the batch, which can affect how quantum gates and transformations are applied to the quantum states.\n",
        "\n",
        "This layer is particularly useful for constructing complex quantum models where certain operations need to be consistently applied across multiple circuits. For example, you may want to apply a sequence of gates to initialize each circuit or to introduce specific transformations that help guide the learning process. The `AddCircuit` layer allows you to achieve this within the TensorFlow framework, maintaining compatibility with classical neural network layers.\n",
        "\n",
        "In practice, the `AddCircuit` layer can be visualized as shown in the following figure, where the additional circuit is either placed at the beginning or the end of each input circuit, depending on whether you choose to prepend or append. This ability to configure circuit positioning within the graph gives researchers and developers a powerful tool to experiment with different circuit configurations and quantum-classical interactions, advancing the capabilities of hybrid quantum-classical models.\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/images/qcnn_1.png?raw=1\" width=\"700\">\n",
        "\n",
        "The following snippet uses this layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhNf0G_OPLqZ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "qubit = cirq.GridQubit(0, 0)\n",
        "\n",
        "# Define some circuits.\n",
        "circuit1 = cirq.Circuit(cirq.X(qubit))\n",
        "circuit2 = cirq.Circuit(cirq.H(qubit))\n",
        "\n",
        "# Convert to a tensor.\n",
        "input_circuit_tensor = tfq.convert_to_tensor([circuit1, circuit2])\n",
        "\n",
        "# Define a circuit that we want to append\n",
        "y_circuit = cirq.Circuit(cirq.Y(qubit))\n",
        "\n",
        "# Instantiate our layer\n",
        "y_appender = tfq.layers.AddCircuit()\n",
        "\n",
        "# Run our circuit tensor through the layer and save the output.\n",
        "output_circuit_tensor = y_appender(input_circuit_tensor, append=y_circuit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShZbRZCXkvk5"
      },
      "source": [
        "## Examine the Input Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImRynsUN4BSG",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "print(tfq.from_tensor(input_circuit_tensor))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkGU4ZTUk4gf"
      },
      "source": [
        "## Examine the Output Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfff6dJp39Fg",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "print(tfq.from_tensor(output_circuit_tensor))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23JeZ7Ns5qy5"
      },
      "source": [
        "While it is possible to run the examples below without using `tfq.layers.AddCircuit`, it's a good opportunity to understand how complex functionality can be embedded into TensorFlow compute graphs."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem overview"
      ],
      "metadata": {
        "id": "gjb4dvKzsILX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcVplt9455Hi"
      },
      "source": [
        "In this project, you’ll create a *cluster state* and train a quantum classifier to determine whether the state is \"excited\" or not. The cluster state is known for being highly entangled, but it’s not necessarily challenging for a classical computer to analyze. For simplicity, this dataset is less complex than the one used in the original research paper, providing an accessible foundation for demonstrating quantum classification.\n",
        "\n",
        "To accomplish this classification task, you’ll implement a deep, [MERA](https://arxiv.org/pdf/quant-ph/0610099.pdf)-like Quantum Convolutional Neural Network (QCNN) architecture. This choice is motivated by two key characteristics of the cluster state:\n",
        "\n",
        "1. **Translational Invariance**: Like a QCNN, the cluster state arranged on a ring exhibits translational invariance, meaning its properties remain consistent even when shifted around the ring. This invariance allows QCNN architectures to process the state effectively without losing information due to shifts in position.\n",
        "   \n",
        "2. **High Entanglement**: The cluster state has a significant level of entanglement across its qubits, which is ideal for demonstrating the QCNN's strength in processing quantum data. The QCNN’s layered structure, inspired by MERA (Multiscale Entanglement Renormalization Ansatz), is designed to reduce entanglement systematically, allowing for an efficient representation of highly entangled states.\n",
        "\n",
        "In this QCNN architecture, the classification task will be achieved by ultimately reading out a single qubit. The QCNN layers will perform entanglement-reducing operations, gradually condensing the information in the cluster state until it can be classified based on the final qubit’s state.\n",
        "\n",
        "***What is an \"Excited\" Cluster State?***\n",
        "\n",
        "In this project, an \"excited\" cluster state is defined as a cluster state where any of the qubits has undergone a rotation along the x-axis via a `cirq.rx` gate. The presence of this rotation, applied to one or more qubits, disrupts the original cluster state configuration, creating an excitation that the classifier will be trained to detect.\n",
        "\n",
        "The illustration below shows a QCNN structure for this task. It includes layers for quantum convolution (QConv) and quantum pooling (QPool), which systematically reduce the complexity of the quantum state while preserving essential information for classification.\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/images/qcnn_2.png?raw=1\" width=\"1000\">\n",
        "\n",
        "***QConv and QPool Layers***\n",
        "\n",
        "In this QCNN model, the **QConv** and **QPool** layers are used to reduce the entanglement in the cluster state, allowing for a more efficient processing of the highly entangled data. These layers function similarly to their classical counterparts but are adapted to operate on quantum data:\n",
        "\n",
        "- **QConv (Quantum Convolution)**: The QConv layer applies a sequence of quantum gates that \"scan\" the state, interacting with neighboring qubits and preserving translational invariance. This operation extracts relevant features from localized regions of the quantum state, analogous to how classical convolutional layers detect patterns in image regions.\n",
        "\n",
        "- **QPool (Quantum Pooling)**: The QPool layer reduces the number of qubits by \"pooling\" information, much like classical pooling layers downsample feature maps. This pooling process helps reduce the complexity of the quantum state and focuses on the essential information, preparing it for the final classification step.\n",
        "\n",
        "These layers are discussed further in the tutorial, providing a breakdown of how each operation functions within the QCNN and contributes to the model’s ability to detect excitations in the cluster state.\n",
        "\n",
        "By following this architecture, you’ll leverage the QCNN's unique ability to manage highly entangled quantum data, enabling it to effectively classify the cluster state as excited or non-excited based on the presence of a rotation applied to its qubits. This project illustrates the QCNN’s strength in detecting subtle variations in quantum states, showcasing a practical application of quantum machine learning in analyzing quantum data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building blocks for TensorFlow"
      ],
      "metadata": {
        "id": "f5BiSoQIsh5I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpqtsGJH_I1d"
      },
      "source": [
        "<img src=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/images/qcnn_3.png?raw=1\" width=\"1000\">\n",
        "\n",
        "To tackle this problem using TensorFlow Quantum, we can build a quantum machine learning model that leverages the hybrid approach of integrating quantum circuits with classical deep learning tools in TensorFlow. The main goal is to design a classifier that can differentiate between an \"excited\" and a \"non-excited\" cluster state, using quantum layers to perform the essential computations. Here’s a breakdown of the key steps to implement this solution:\n",
        "\n",
        "1. **Input Preparation**:\n",
        "   - The model input is a *circuit tensor*, a batch of quantum circuits that serve as the dataset for the model. Each circuit tensor will represent either an \"excited\" or \"non-excited\" cluster state.\n",
        "   - To create the distinction between these two states, each circuit tensor will either be an empty circuit (indicating a non-excited state) or contain an X gate applied to a particular qubit (representing an excitation). This X gate, or Pauli-X operation, flips the qubit's state, introducing an excitation in the cluster state.\n",
        "   - This setup creates a clear, binary classification problem: circuits with an X gate on any qubit are labeled as excited, while those without the X gate are labeled as non-excited.\n",
        "\n",
        "2. **Building the Quantum Model Components**:\n",
        "   - TensorFlow Quantum provides specialized layers, including `tfq.layers.AddCircuit`, that make it easy to build and manipulate quantum circuits within the TensorFlow computation graph.\n",
        "   - In this model, `tfq.layers.AddCircuit` layers are used to define and add quantum components to the input circuit tensor. Each `AddCircuit` layer can append or prepend a predefined set of quantum gates or operations to the input circuits, allowing for flexible circuit construction.\n",
        "   - These added circuits can implement necessary operations for the quantum convolutional neural network (QCNN), such as the Quantum Convolution (QConv) and Quantum Pooling (QPool) layers. By stacking `AddCircuit` layers, you can build the QCNN structure, enabling the model to progressively extract features from the input circuits.\n",
        "\n",
        "3. **Inference with a Parametrized Quantum Circuit (PQC) Layer**:\n",
        "   - For the final inference step, a `tfq.layers.PQC` (Parametrized Quantum Circuit) layer is used. The PQC layer applies a quantum circuit with trainable parameters and measures specific observables as the output.\n",
        "   - In this case, the PQC layer measures the expectation value of the Pauli-Z operator, denoted as ⟨𝑍⟩. This measurement provides an output value that can be used for binary classification.\n",
        "   - The model interprets the result of ⟨𝑍⟩ as follows:\n",
        "     - If ⟨𝑍⟩ is close to 1, it corresponds to a label of 1, indicating an \"excited\" state.\n",
        "     - If ⟨𝑍⟩ is close to -1, it corresponds to a label of -1, indicating a \"non-excited\" state.\n",
        "   - This classification rule allows the PQC layer to output a binary prediction based on the input circuit’s quantum state.\n",
        "\n",
        "***Overview of Model Architecture***\n",
        "\n",
        "To summarize, this approach involves creating a quantum-classical hybrid model in TensorFlow Quantum. The architecture includes the following components:\n",
        "\n",
        "- **Input Layer**: A circuit tensor representing either an empty circuit (non-excited) or a circuit with an X gate applied to one qubit (excited).\n",
        "- **Quantum Layers (AddCircuit Layers)**: Layers that add specific quantum operations to the circuits, forming the QConv and QPool layers in the QCNN architecture. These operations process the input circuit, gradually reducing entanglement and preparing it for the final classification.\n",
        "- **Output Layer (PQC Layer)**: A `tfq.layers.PQC` layer that performs a measurement of ⟨𝑍⟩ on the output qubit, determining whether the state is excited or non-excited based on the measurement outcome.\n",
        "\n",
        "This approach highlights the power of TensorFlow Quantum in constructing and training hybrid quantum-classical models. By combining circuit tensors, `AddCircuit` layers, and PQC layers, TensorFlow Quantum enables the design of sophisticated quantum machine learning models that can analyze and classify quantum data effectively. This model is designed to be straightforward yet effective for tasks involving quantum state classification, illustrating the utility of quantum neural networks in analyzing highly entangled quantum data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "10HVmQ7ds37o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa7Q3m_ThDgO"
      },
      "source": [
        "Before constructing the model, it’s essential to generate the dataset that will be used for training and evaluating the quantum classifier. In this case, the dataset will consist of *excited* and *non-excited* cluster states. Here’s how this dataset is created, along with the criteria for labeling each data point:\n",
        "\n",
        "1. **Cluster State Setup**:\n",
        "   - The cluster state serves as the base state for each sample in the dataset. A cluster state is a highly entangled quantum state created by applying a sequence of controlled-Z (CZ) gates to a set of qubits initialized in the |+⟩ state (created using Hadamard gates). In this setup, the cluster state acts as the baseline to which excitations may or may not be applied.\n",
        "\n",
        "2. **Adding Excitations with `cirq.rx` Gates**:\n",
        "   - To introduce excitations, rotations along the x-axis are applied to one or more qubits in the cluster state. Specifically, the `cirq.rx` gate is used to perform an x-axis rotation by a certain angle.\n",
        "   - Each rotation has a specific angle parameter. The magnitude of this rotation determines whether it qualifies as an \"excitation\" or not:\n",
        "     - If the rotation angle is *large enough*, the state is considered excited and is labeled `1`.\n",
        "     - If the rotation angle is *not large enough*, the state is considered non-excited and is labeled `-1`.\n",
        "   - This distinction allows for a binary classification problem, where the goal is to detect whether the cluster state contains a significant excitation or not.\n",
        "\n",
        "3. **Labeling Criteria**:\n",
        "   - The threshold for what constitutes a “large enough” rotation is defined based on experimental design. For instance, rotations greater than π/4 might be labeled as `1` (excited), while rotations less than or equal to π/4 are labeled as `-1` (non-excited). This threshold can be adjusted based on the specifics of the classification task and the desired sensitivity.\n",
        "   - By setting up this labeling criteria, each sample in the dataset receives a clear label (`1` for excited or `-1` for non-excited), allowing the model to learn the difference between the two states.\n",
        "\n",
        "4. **Generating the Dataset**:\n",
        "   - To build the dataset, a series of cluster states are created, with varying x-axis rotations applied to different qubits according to the threshold criteria.\n",
        "   - For each sample, a cluster state is generated and an `cirq.rx` rotation (with a random angle) is applied to a randomly selected qubit. Depending on the angle of rotation, the sample is labeled accordingly.\n",
        "   - This process is repeated to generate a balanced dataset of excited and non-excited states, with labels of `1` and `-1`, respectively.\n",
        "\n",
        "5. **Purpose of the Dataset**:\n",
        "   - This dataset allows the quantum classifier to learn how to distinguish between different states based on subtle changes in the quantum state caused by x-axis rotations. By training on this dataset, the model will learn to detect significant excitations in cluster states, a useful capability for quantum data analysis.\n",
        "\n",
        "In summary, this data generation process creates a labeled dataset of cluster states with and without excitations. Excitations are introduced using `cirq.rx` gates, and the rotation angle serves as the basis for labeling each sample. This simplified dataset provides an accessible way to train the quantum classifier, as it allows the model to learn how to identify states with significant excitations from the rest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUrvTCU1hDgP",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def generate_data(qubits):\n",
        "    \"\"\"Generate training and testing data.\"\"\"\n",
        "    n_rounds = 20  # Produces n_rounds * n_qubits datapoints.\n",
        "    excitations = []\n",
        "    labels = []\n",
        "    for n in range(n_rounds):\n",
        "        for bit in qubits:\n",
        "            rng = np.random.uniform(-np.pi, np.pi)\n",
        "            excitations.append(cirq.Circuit(cirq.rx(rng)(bit)))\n",
        "            labels.append(1 if (-np.pi / 2) <= rng <= (np.pi / 2) else -1)\n",
        "\n",
        "    split_ind = int(len(excitations) * 0.7)\n",
        "    train_excitations = excitations[:split_ind]\n",
        "    test_excitations = excitations[split_ind:]\n",
        "\n",
        "    train_labels = labels[:split_ind]\n",
        "    test_labels = labels[split_ind:]\n",
        "\n",
        "    return tfq.convert_to_tensor(train_excitations), np.array(train_labels), \\\n",
        "        tfq.convert_to_tensor(test_excitations), np.array(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGsDkZnrhDgS"
      },
      "source": [
        "You can see that just like with regular machine learning you create a training and testing set to use to benchmark the model. You can quickly look at some datapoints with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLJ-JHOihDgT",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "sample_points, sample_labels, _, __ = generate_data(cirq.GridQubit.rect(1, 4))\n",
        "print('Input:', tfq.from_tensor(sample_points)[0], 'Output:', sample_labels[0])\n",
        "print('Input:', tfq.from_tensor(sample_points)[1], 'Output:', sample_labels[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFiRlDt_0-DL"
      },
      "source": [
        "## Define layers\n",
        "\n",
        "Now define the layers shown in the figure above in TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster State"
      ],
      "metadata": {
        "id": "i443SMFYtQ4i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2B9geIqLWHK"
      },
      "source": [
        "The first step is to define the <a href=\"https://arxiv.org/pdf/quant-ph/0504097.pdf\" class=\"external\">cluster state</a> using <a href=\"https://github.com/quantumlib/Cirq\" class=\"external\">Cirq</a>, a Google-provided framework for programming quantum circuits. Since this is a static part of the model, embed it using the `tfq.layers.AddCircuit` functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpQwVWKazU8g",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def cluster_state_circuit(bits):\n",
        "    \"\"\"Return a cluster state on the qubits in `bits`.\"\"\"\n",
        "    circuit = cirq.Circuit()\n",
        "    circuit.append(cirq.H.on_each(bits))\n",
        "    for this_bit, next_bit in zip(bits, bits[1:] + [bits[0]]):\n",
        "        circuit.append(cirq.CZ(this_bit, next_bit))\n",
        "    return circuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9qX1uN740vJ"
      },
      "source": [
        "Display a cluster state circuit for a rectangle of <a href=\"https://cirq.readthedocs.io/en/stable/generated/cirq.GridQubit.html\" class=\"external\"><code>cirq.GridQubit</code></a>s:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tZt0aAO4r4F",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "SVGCircuit(cluster_state_circuit(cirq.GridQubit.rect(1, 4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows a quantum circuit with four qubits (labeled `(0, 0)`, `(0, 1)`, `(0, 2)`, and `(0, 3)`) organized in a grid-like structure. Each qubit is initialized with a Hadamard gate (`H`), followed by a series of controlled operations that form an entangled cluster state. Here’s a breakdown of the components and structure of this circuit:\n",
        "\n",
        "***Circuit Breakdown***\n",
        "\n",
        "1. **Hadamard Gates (`H`)**:\n",
        "   - Each qubit has a Hadamard gate applied at the beginning. The Hadamard gate creates a superposition for each qubit, placing them in an equal probability state of |0⟩ and |1⟩.\n",
        "   - Applying Hadamard gates to all qubits prepares them in a |+⟩ state, which serves as the basis for building entanglement across the qubits.\n",
        "\n",
        "2. **Controlled-Z (CZ) Gates**:\n",
        "   - The black dots connected by lines represent controlled operations, likely Controlled-Z (CZ) gates, which are common in cluster state generation.\n",
        "   - In a CZ gate, the phase of the target qubit is flipped (from |+⟩ to |−⟩) if the control qubit is in the |1⟩ state. This gate creates entanglement between pairs of qubits.\n",
        "   - The placement of the CZ gates in this circuit follows a pattern that entangles each qubit with its neighboring qubits, creating a highly entangled state.\n",
        "\n",
        "3. **Layered Structure**:\n",
        "   - The circuit shows layers of entangling gates, with each layer connecting different pairs of qubits. This layered approach gradually builds up the entanglement in the system.\n",
        "   - By arranging the CZ gates in this pattern, the circuit entangles the qubits in a structure similar to a 1D cluster state, where each qubit is entangled with its immediate neighbors.\n",
        "\n",
        "***Purpose of the Circuit***\n",
        "\n",
        "This setup is typical for creating a *cluster state*, a foundational entangled state in quantum computing. Cluster states serve as a starting point for various quantum algorithms, particularly those in measurement-based quantum computation. In the context of a Quantum Convolutional Neural Network (QCNN), this entangled state acts as the input state, which will later undergo further transformations (quantum convolution and pooling) to extract features for classification.\n",
        "\n",
        "***Key Points***\n",
        "\n",
        "- **Cluster State Preparation**: The initial Hadamard gates put each qubit in superposition, and the CZ gates entangle them, creating a cluster state.\n",
        "- **Translational Invariance**: The arrangement of gates makes the cluster state translationally invariant, meaning that the pattern of entanglement remains consistent across the qubits.\n",
        "- **Input for QCNN**: This entangled state will serve as the input for a QCNN, where further layers will be applied to detect specific properties (like excitations) in the state.\n",
        "\n",
        "In summary, this circuit creates a 1D cluster state using Hadamard and CZ gates. It initializes the qubits in superposition and then entangles them with neighboring qubits, forming the base state for further processing in the quantum convolutional network."
      ],
      "metadata": {
        "id": "Q1eyMCC8zRZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QCNN Layers"
      ],
      "metadata": {
        "id": "iVr8UGgZtrK5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xElWnRf1ZC7"
      },
      "source": [
        "To construct the Quantum Convolutional Neural Network (QCNN) as outlined in the [Cong and Lukin QCNN paper](https://arxiv.org/abs/1810.03787), we need to define a series of layers that will process the cluster state and detect excitations. The QCNN architecture includes layers inspired by classical CNNs but adapted to operate on quantum data. This includes *quantum convolution* and *quantum pooling* layers, which reduce the complexity of the entangled state while preserving essential information for classification.\n",
        "\n",
        "Here’s a step-by-step guide to setting up these layers, along with the prerequisites:\n",
        "\n",
        "***1. Prerequisites: One- and Two-Qubit Parameterized Unitary Matrices***\n",
        "\n",
        "The [Tucci paper](https://arxiv.org/abs/quant-ph/0507171) introduces parameterized unitary matrices for one- and two-qubit gates. These matrices allow us to represent general quantum operations in a parameterized form, which is essential for building trainable quantum layers in the QCNN. Below are the types of parameterized gates needed:\n",
        "\n",
        "- **One-Qubit Unitary Matrix**:\n",
        "  - A general one-qubit gate can be represented by a parameterized unitary matrix $ U(\\theta, \\phi, \\lambda) $, which has three parameters:\n",
        "     \n",
        "  $$ U(\\theta, \\phi, \\lambda) = \\begin{pmatrix} \\cos(\\theta/2) & -e^{i\\lambda}\\sin(\\theta/2) \\\\ e^{i\\phi}\\sin(\\theta/2) & e^{i(\\phi + \\lambda)}\\cos(\\theta/2) \\end{pmatrix} $$\n",
        "\n",
        "  - In Cirq, this can be implemented with a sequence of `cirq.rx`, `cirq.ry`, and `cirq.rz` rotations, where the parameters $( \\theta ), ( \\phi )$, and $( \\lambda )$ can be optimized during training.\n",
        "\n",
        "- **Two-Qubit Parameterized Unitary Matrix**:\n",
        "  - A general two-qubit gate is more complex, with multiple parameters representing interactions between qubits. The Controlled-Z (CZ) and Controlled-X (CX) gates are commonly used, but parameterized versions (using, for example, a combination of `cirq.CZPowGate` and rotation gates) are used to add flexibility.\n",
        "  - For instance, a controlled rotation can be represented with:\n",
        "    ```python\n",
        "    import cirq\n",
        "\n",
        "    def parameterized_two_qubit_gate(qubit1, qubit2, theta):\n",
        "        yield cirq.CZ(qubit1, qubit2)\n",
        "        yield cirq.rx(theta)(qubit1)\n",
        "        yield cirq.rx(theta)(qubit2)\n",
        "    ```\n",
        "  - By making these gates parameterized, we allow the model to learn complex relationships within the quantum data, which is essential for accurate classification.\n",
        "\n",
        "***2. Quantum Convolution Layer (QConv)***\n",
        "\n",
        "The Quantum Convolution (QConv) layer is analogous to the convolutional layer in classical CNNs. In QCNNs, the QConv layer applies a sequence of one- and two-qubit parameterized gates to local regions of the cluster state. This layer \"scans\" over neighboring qubits, entangling and transforming their states based on the learned parameters. Here’s how to implement a QConv layer:\n",
        "\n",
        "- **Implementation**:\n",
        "  - Select a set of neighboring qubits (usually pairs) and apply the parameterized one- and two-qubit gates defined above.\n",
        "  - For example:\n",
        "    ```python\n",
        "    def qconv_layer(qubits, parameters):\n",
        "        # Apply one-qubit gates\n",
        "        for i, qubit in enumerate(qubits):\n",
        "            yield cirq.rx(parameters[i])(qubit)\n",
        "        \n",
        "        # Apply two-qubit gates between pairs\n",
        "        for i in range(len(qubits) - 1):\n",
        "            yield parameterized_two_qubit_gate(qubits[i], qubits[i + 1], parameters[len(qubits) + i])\n",
        "    ```\n",
        "  - This layer can be implemented as a function in Cirq that takes a list of qubits and a set of parameters, returning the QConv layer as a sequence of parameterized quantum operations.\n",
        "\n",
        "***3. Quantum Pooling Layer (QPool)***\n",
        "\n",
        "The Quantum Pooling (QPool) layer reduces the number of qubits, similar to how classical pooling layers reduce the spatial dimensions in CNNs. A general parameterized two-qubit pooling operation is used here. This operation entangles pairs of qubits and then discards one qubit from each pair, preserving the important features while reducing dimensionality.\n",
        "\n",
        "- **Implementation of Parameterized QPool Operation**:\n",
        "  - To achieve pooling, a common approach is to apply a parameterized two-qubit gate to a pair of qubits, then measure or discard one of them.\n",
        "  - In a MERA-like structure, one qubit can be rotated conditionally based on the state of the other, and then one qubit is discarded. This operation can be parameterized to allow flexibility in the pooling behavior.\n",
        "  - Here’s an example implementation:\n",
        "    ```python\n",
        "    def qpool_layer(qubits, parameters):\n",
        "        new_qubits = []\n",
        "        for i in range(0, len(qubits), 2):\n",
        "            q1, q2 = qubits[i], qubits[i + 1]\n",
        "            yield cirq.CZPowGate(exponent=parameters[i])(q1, q2)\n",
        "            yield cirq.rx(parameters[i + 1])(q1)\n",
        "            # Keep q1 and discard q2 (or vice versa)\n",
        "            new_qubits.append(q1)\n",
        "        return new_qubits\n",
        "    ```\n",
        "  - This function applies a parameterized CZ gate between each pair of qubits, followed by a rotation, and then \"pools\" by retaining only one qubit from each pair.\n",
        "\n",
        "***4. Final Layer: Measurement and Readout***\n",
        "\n",
        "After applying multiple layers of QConv and QPool, the final layer of the QCNN performs a measurement on a single qubit, which provides the classification result.\n",
        "\n",
        "- **Readout with `tfq.layers.PQC`**:\n",
        "  - The measurement layer can be implemented using TensorFlow Quantum’s `tfq.layers.PQC` (Parameterized Quantum Circuit) layer. This layer measures the expectation value of an observable, such as the Pauli-Z operator, to produce a result for classification.\n",
        "  - The PQC layer takes the quantum circuit with trainable parameters as input and outputs a real value representing the measurement result. This output can then be interpreted for binary classification:\n",
        "    ```python\n",
        "    import tensorflow_quantum as tfq\n",
        "    import tensorflow as tf\n",
        "\n",
        "    # Define the input layer for the quantum circuits\n",
        "    input_layer = tf.keras.Input(shape=(), dtype=tf.dtypes.string)\n",
        "\n",
        "    # Apply a PQC layer for final readout\n",
        "    measurement_layer = tfq.layers.PQC(\n",
        "        model_circuit, observables=[cirq.Z(final_qubit)])(input_layer)\n",
        "    ```\n",
        "\n",
        "***Summary of the QCNN Architecture***\n",
        "\n",
        "The complete QCNN model, inspired by the Cong and Lukin paper, includes the following layers:\n",
        "\n",
        "1. **Cluster State Layer**: Uses `tfq.layers.AddCircuit` to initialize each input with a predefined cluster state.\n",
        "2. **Quantum Convolution (QConv) Layers**: Applies parameterized one- and two-qubit operations to local regions, entangling and transforming qubits to extract features.\n",
        "3. **Quantum Pooling (QPool) Layers**: Uses parameterized two-qubit operations to reduce the number of qubits by retaining only one qubit from each pair after pooling.\n",
        "4. **Measurement and Readout**: Uses `tfq.layers.PQC` to measure the expectation value of the final qubit, providing a classification output based on the observed state.\n",
        "\n",
        "By stacking these layers, you can build a powerful QCNN that leverages entanglement and parameterized operations to classify highly entangled states, such as the cluster state, and detect excitations. This model illustrates the potential of quantum neural networks in capturing complex patterns within quantum data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNRGOqky2exY",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def one_qubit_unitary(bit, symbols):\n",
        "    \"\"\"Make a Cirq circuit enacting a rotation of the bloch sphere about the X,\n",
        "    Y and Z axis, that depends on the values in `symbols`.\n",
        "    \"\"\"\n",
        "    return cirq.Circuit(\n",
        "        cirq.X(bit)**symbols[0],\n",
        "        cirq.Y(bit)**symbols[1],\n",
        "        cirq.Z(bit)**symbols[2])\n",
        "\n",
        "\n",
        "def two_qubit_unitary(bits, symbols):\n",
        "    \"\"\"Make a Cirq circuit that creates an arbitrary two qubit unitary.\"\"\"\n",
        "    circuit = cirq.Circuit()\n",
        "    circuit += one_qubit_unitary(bits[0], symbols[0:3])\n",
        "    circuit += one_qubit_unitary(bits[1], symbols[3:6])\n",
        "    circuit += [cirq.ZZ(*bits)**symbols[6]]\n",
        "    circuit += [cirq.YY(*bits)**symbols[7]]\n",
        "    circuit += [cirq.XX(*bits)**symbols[8]]\n",
        "    circuit += one_qubit_unitary(bits[0], symbols[9:12])\n",
        "    circuit += one_qubit_unitary(bits[1], symbols[12:])\n",
        "    return circuit\n",
        "\n",
        "\n",
        "def two_qubit_pool(source_qubit, sink_qubit, symbols):\n",
        "    \"\"\"Make a Cirq circuit to do a parameterized 'pooling' operation, which\n",
        "    attempts to reduce entanglement down from two qubits to just one.\"\"\"\n",
        "    pool_circuit = cirq.Circuit()\n",
        "    sink_basis_selector = one_qubit_unitary(sink_qubit, symbols[0:3])\n",
        "    source_basis_selector = one_qubit_unitary(source_qubit, symbols[3:6])\n",
        "    pool_circuit.append(sink_basis_selector)\n",
        "    pool_circuit.append(source_basis_selector)\n",
        "    pool_circuit.append(cirq.CNOT(source_qubit, sink_qubit))\n",
        "    pool_circuit.append(sink_basis_selector**-1)\n",
        "    return pool_circuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoG0a3U_2qGA"
      },
      "source": [
        "To see what you created, print out the one-qubit unitary circuit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5uhvF-g2rpZ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "SVGCircuit(one_qubit_unitary(cirq.GridQubit(0, 0), sympy.symbols('x0:3')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows two sections of code defining circuits in a quantum convolutional neural network (QCNN) model. The primary focus here is on defining parameterized one-qubit and two-qubit unitary operations that can be used in the quantum pooling layers of the QCNN. Let’s go through each part in detail.\n",
        "\n",
        "***1. One-Qubit Unitary Circuit***\n",
        "\n",
        "The first circuit displayed is the output of the `one_qubit_unitary` function, which represents a parameterized one-qubit unitary operation. This is a foundational component in quantum convolution and pooling operations.\n",
        "\n",
        "- **Structure**:\n",
        "  - The circuit consists of three parameterized rotation gates: \\( X^{x0} \\), \\( Y^{x1} \\), and \\( Z^{x2} \\).\n",
        "  - These gates are controlled by three separate parameters (`x0`, `x1`, and `x2`), allowing the one-qubit gate to be tuned during training.\n",
        "\n",
        "- **Purpose**:\n",
        "  - This one-qubit unitary is flexible, enabling the QCNN model to learn an optimal transformation for each qubit during training.\n",
        "  - By applying rotations along different axes (X, Y, and Z), this circuit can represent any arbitrary one-qubit transformation. This is essential for encoding and manipulating information in each qubit.\n",
        "\n",
        "***2. Two-Qubit Pooling Operation***\n",
        "\n",
        "The code also defines a `two_qubit_pool` function, which constructs a parameterized *quantum pooling operation* using two qubits (`source_qubit` and `sink_qubit`). Pooling is essential in a QCNN to reduce the qubit count, similar to how pooling in classical CNNs reduces the dimensionality of feature maps.\n",
        "\n",
        "- **Structure**:\n",
        "  - The two-qubit pooling operation begins by applying a parameterized one-qubit unitary transformation on each qubit using the `one_qubit_unitary` function.\n",
        "  - The **`CNOT` gate** is then applied with `source_qubit` as the control and `sink_qubit` as the target, creating an entanglement between the two qubits. This gate helps transfer information between the qubits in a controlled manner.\n",
        "  - The **inverse of the sink basis selector** is then applied to `sink_qubit` to \"undo\" the initial operation, isolating the impact of the pooling operation on `source_qubit`.\n",
        "\n",
        "- **Purpose**:\n",
        "  - This pooling operation reduces entanglement by selectively retaining information from the `source_qubit` and partially \"resetting\" the `sink_qubit`.\n",
        "  - The use of parameterized one-qubit gates, along with the entangling CNOT gate, allows the pooling operation to adapt based on training, potentially discarding less relevant information from one of the qubits while preserving useful features in the other.\n",
        "\n",
        "***Summary***\n",
        "\n",
        "- **One-Qubit Unitary**: A parameterized circuit with three rotation gates (X, Y, Z) that allows each qubit to undergo a flexible transformation. This enables the model to adjust each qubit’s state based on learned parameters.\n",
        "  \n",
        "- **Two-Qubit Pooling Operation**:\n",
        "  - A parameterized circuit that operates on a pair of qubits.\n",
        "  - It applies transformations to each qubit, entangles them with a CNOT gate, and uses an inverse operation to reduce entanglement selectively.\n",
        "  - This operation reduces the number of qubits in the QCNN, pooling information to focus on key features while discarding less relevant information.\n",
        "\n",
        "These circuits form the building blocks of the QCNN’s quantum convolution and pooling layers, allowing it to process and reduce the dimensionality of quantum data in a flexible, trainable way."
      ],
      "metadata": {
        "id": "jE4ip4hbz39g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWuMb_Us8ar2"
      },
      "source": [
        "And the two-qubit unitary circuit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJTdRrfS2uIo",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "SVGCircuit(two_qubit_unitary(cirq.GridQubit.rect(1, 2), sympy.symbols('x0:15')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows a quantum circuit representing a two-qubit parameterized unitary operation, with a mix of single-qubit and two-qubit gates applied in sequence to two qubits `(0, 0)` and `(0, 1)`. This circuit is intended for use in a Quantum Convolutional Neural Network (QCNN), where such parameterized circuits play a crucial role in pooling and entangling qubits. Let’s break down the components of this circuit.\n",
        "\n",
        "***Overview of the Circuit***\n",
        "\n",
        "The circuit includes:\n",
        "1. **Parameterized Single-Qubit Rotations (X, Y, Z Gates)**:\n",
        "   - Applied independently on each qubit to allow for flexible transformations controlled by parameters.\n",
        "2. **Parameterized Two-Qubit Gates (ZZ, YY, XX Gates)**:\n",
        "   - Applied between the two qubits, creating entanglement and interactions based on adjustable parameters.\n",
        "\n",
        "***Detailed Breakdown***\n",
        "\n",
        "1. **Single-Qubit Gates on `(0, 0)` and `(0, 1)`**:\n",
        "   - The circuit starts with parameterized single-qubit gates (`X`, `Y`, `Z`) applied to each qubit. These are indicated by symbols such as `X^x0`, `Y^x1`, and `Z^x2`.\n",
        "   - These gates allow each qubit’s state to be independently rotated around the X, Y, and Z axes, with parameters controlling the extent of each rotation.\n",
        "   - These single-qubit rotations prepare the individual qubits for the two-qubit operations that follow.\n",
        "\n",
        "2. **Two-Qubit Gates (ZZ, YY, XX)**:\n",
        "   - The circuit includes several two-qubit gates, each parameterized and entangling the qubits in specific ways:\n",
        "     - **ZZ Gate**: Represents a controlled rotation between the two qubits around the Z axis, indicated as `ZZ^x4`.\n",
        "     - **YY Gate**: Represents a controlled rotation around the Y axis, indicated as `YY^x5`.\n",
        "     - **XX Gate**: Represents a controlled rotation around the X axis, indicated as `XX^x6`.\n",
        "   - These two-qubit gates are applied with parameters to tune the entangling strength, allowing for adaptive interactions between the qubits during training.\n",
        "   - The use of multiple two-qubit gates with different axes of control (Z, Y, X) provides a richer set of interactions between qubits, enabling the circuit to capture complex entangled states.\n",
        "\n",
        "3. **Additional Single-Qubit Gates**:\n",
        "   - After the two-qubit interactions, further single-qubit `X`, `Y`, and `Z` gates are applied to each qubit with additional parameters, allowing for final rotations.\n",
        "   - These additional single-qubit gates provide further control over each qubit’s state after entangling interactions, helping to encode information more effectively.\n",
        "\n",
        "***Purpose of the Circuit***\n",
        "\n",
        "This two-qubit parameterized circuit is likely used for pooling or encoding operations within a QCNN. Here’s how it contributes to the overall QCNN architecture:\n",
        "\n",
        "- **Flexible Transformation and Entanglement**:\n",
        "  - The circuit includes a series of parameterized operations that can be adjusted during training, making it possible for the network to learn useful transformations and patterns within the quantum data.\n",
        "  - The combination of single- and two-qubit gates allows the model to entangle and disentangle the qubits as needed, essential for reducing dimensionality in pooling layers.\n",
        "  \n",
        "- **Learnable Parameters**:\n",
        "  - Each gate in this circuit has a learnable parameter, enabling the model to adapt the transformation and entanglement strength based on the data. This makes the circuit flexible and adaptable to the task at hand.\n",
        "\n",
        "- **Pooling or Feature Extraction**:\n",
        "  - In the context of a QCNN, this two-qubit unitary could be part of a pooling layer, where information from two qubits is combined or simplified into a lower-dimensional representation. This reduces the number of qubits while preserving key information.\n",
        "\n",
        "***Summary***\n",
        "\n",
        "This circuit is a sophisticated two-qubit parameterized unitary operation, featuring a combination of single-qubit rotations and entangling two-qubit gates. Each gate is controlled by a parameter, allowing the circuit to learn and adapt based on training data. This circuit can be used as part of a quantum pooling layer in a QCNN, helping reduce the complexity of the quantum state by pooling information from two qubits into one while maintaining critical features."
      ],
      "metadata": {
        "id": "3h_wB0eH0ZGE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXQD1R_V8jyk"
      },
      "source": [
        "And the two-qubit pooling circuit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOHRbkvH2xGK",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "SVGCircuit(two_qubit_pool(*cirq.GridQubit.rect(1, 2), sympy.symbols('x0:6')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows a two-qubit quantum circuit designed for use in a Quantum Convolutional Neural Network (QCNN). This circuit appears to be a pooling layer that operates on two qubits labeled `(0, 0)` and `(0, 1)`, where parameterized single-qubit and two-qubit gates are applied in sequence. Let’s go through each part of this circuit step-by-step.\n",
        "\n",
        "***Circuit Components and Structure***\n",
        "\n",
        "1. **Parameterized Single-Qubit Gates on Qubits `(0, 0)` and `(0, 1)`**:\n",
        "   - The circuit begins with three parameterized single-qubit rotation gates applied to each qubit:\n",
        "     - On qubit `(0, 0)`:\n",
        "       - `X^x0`, `Y^x1`, `Z^x2` indicate rotations around the X, Y, and Z axes, controlled by parameters `x0`, `x1`, and `x2`.\n",
        "     - On qubit `(0, 1)`:\n",
        "       - `X^x3`, `Y^x4`, `Z^x5` similarly represent rotations around each axis with parameters `x3`, `x4`, and `x5`.\n",
        "   - These parameterized single-qubit rotations allow the model to adjust each qubit’s state individually based on the training data. By applying rotations around different axes, these gates enable a wide range of possible transformations for each qubit.\n",
        "\n",
        "2. **Two-Qubit CNOT Gate**:\n",
        "   - After the initial single-qubit rotations, a CNOT (controlled-NOT) gate is applied with qubit `(0, 0)` as the control and qubit `(0, 1)` as the target.\n",
        "   - The CNOT gate creates an entanglement between the two qubits, depending on the state of the control qubit. This entanglement is crucial for pooling operations, as it allows information to be transferred and shared between the qubits.\n",
        "   - In the context of a QCNN, this CNOT gate allows the two qubits to interact, enabling the circuit to perform more complex operations that depend on the combined state of both qubits.\n",
        "\n",
        "3. **Inverse Rotations on Qubit `(0, 1)`**:\n",
        "   - After the CNOT gate, the circuit applies a set of rotations with negative exponents on qubit `(0, 1)`, effectively acting as inverse operations to undo the original transformations applied at the start of the circuit.\n",
        "     - These inverse operations are:\n",
        "       - `Z^-x2`, `Y^-x1`, and `X^-x0`.\n",
        "   - These inverse gates \"cancel out\" the effect of the initial single-qubit rotations on qubit `(0, 1)`. This selective reset allows the circuit to retain the impact of the entangling CNOT gate on qubit `(0, 0)`, effectively \"pooling\" information into a single qubit by preserving relevant transformations.\n",
        "\n",
        "***Purpose and Function of the Circuit***\n",
        "\n",
        "This two-qubit pooling circuit performs several key functions in the context of a QCNN:\n",
        "\n",
        "- **Pooling Operation**:\n",
        "  - The purpose of pooling in QCNNs is to reduce the number of qubits while retaining essential information. This is similar to how pooling in classical CNNs reduces spatial dimensions while preserving important features.\n",
        "  - By using inverse rotations on one of the qubits, the circuit effectively resets it while retaining the entangled information on the other qubit. This reduces dimensionality in a controlled manner, allowing for efficient data compression.\n",
        "\n",
        "- **Parameterization and Learnability**:\n",
        "  - The parameters (`x0` through `x5`) provide flexibility, allowing the circuit to adapt during training. The model can optimize these parameters to maximize performance on a given task.\n",
        "  - The presence of parameterized gates makes the circuit highly adaptable, as it can learn optimal rotations for feature extraction based on the input data.\n",
        "\n",
        "- **Entanglement and Information Transfer**:\n",
        "  - The CNOT gate entangles the two qubits, transferring information between them. Combined with the subsequent reset of one qubit, this circuit structure enables the model to capture interactions between qubits effectively and retain useful features in a reduced form.\n",
        "\n",
        "***Summary***\n",
        "\n",
        "- **Single-Qubit Gates**: The initial parameterized rotations allow each qubit to undergo a unique transformation, creating a wide variety of possible quantum states.\n",
        "- **CNOT Gate**: The CNOT gate entangles the two qubits, facilitating interaction and shared information.\n",
        "- **Inverse Rotations**: The final set of inverse rotations \"cancels out\" transformations on one qubit, enabling a selective reset that retains information in the other qubit, achieving a pooling effect.\n",
        "\n",
        "This circuit serves as a two-qubit pooling layer in a QCNN, enabling dimensionality reduction while preserving critical features through entanglement and selective resetting. The combination of learnable parameters and entangling operations allows the QCNN to effectively process quantum data and retain meaningful patterns for classification or other quantum machine learning tasks."
      ],
      "metadata": {
        "id": "_x4DC_h706ks"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzVauXWD3v8C"
      },
      "source": [
        "#### Quantum Convolution\n",
        "\n",
        "As in the <a href=\"https://arxiv.org/abs/1810.03787\" class=\"external\">Cong and Lukin</a> paper, define the 1D quantum convolution as the application of a two-qubit parameterized unitary to every pair of adjacent qubits with a stride of one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Fa19Lzb3wnR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def quantum_conv_circuit(bits, symbols):\n",
        "    \"\"\"Quantum Convolution Layer following the above diagram.\n",
        "    Return a Cirq circuit with the cascade of `two_qubit_unitary` applied\n",
        "    to all pairs of qubits in `bits` as in the diagram above.\n",
        "    \"\"\"\n",
        "    circuit = cirq.Circuit()\n",
        "    for first, second in zip(bits[0::2], bits[1::2]):\n",
        "        circuit += two_qubit_unitary([first, second], symbols)\n",
        "    for first, second in zip(bits[1::2], bits[2::2] + [bits[0]]):\n",
        "        circuit += two_qubit_unitary([first, second], symbols)\n",
        "    return circuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTzOm_t394Gj"
      },
      "source": [
        "Display the (very horizontal) circuit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi6q2nmY3z_U",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "SVGCircuit(\n",
        "    quantum_conv_circuit(cirq.GridQubit.rect(1, 8), sympy.symbols('x0:15')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3svBAfap4xhP"
      },
      "source": [
        "#### Quantum Pooling\n",
        "\n",
        "A quantum pooling layer pools from $N$ qubits to $\\frac{N}{2}$ qubits using the two-qubit pool defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jD3fgcWO4yEU",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def quantum_pool_circuit(source_bits, sink_bits, symbols):\n",
        "    \"\"\"A layer that specifies a quantum pooling operation.\n",
        "    A Quantum pool tries to learn to pool the relevant information from two\n",
        "    qubits onto 1.\n",
        "    \"\"\"\n",
        "    circuit = cirq.Circuit()\n",
        "    for source, sink in zip(source_bits, sink_bits):\n",
        "        circuit += two_qubit_pool(source, sink, symbols)\n",
        "    return circuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX83NHDP_Q_Z"
      },
      "source": [
        "Examine a pooling component circuit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFXow2OX47O5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "test_bits = cirq.GridQubit.rect(1, 8)\n",
        "\n",
        "SVGCircuit(\n",
        "    quantum_pool_circuit(test_bits[:4], test_bits[4:], sympy.symbols('x0:6')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This displays a multi-layer quantum circuit, designed to serve as a *quantum pooling layer* within a Quantum Convolutional Neural Network (QCNN). The circuit appears to have eight qubits, each undergoing a series of parameterized single-qubit rotations, two-qubit gates, and controlled operations. This structure aligns with the general purpose of QCNNs, which is to perform feature extraction and dimensionality reduction in quantum data, similar to pooling and convolution operations in classical CNNs. Let's analyze this circuit layer by layer.\n",
        "\n",
        "***Structure and Components of the Circuit***\n",
        "\n",
        "1. **Single-Qubit Parameterized Rotations**:\n",
        "   - Each qubit in the circuit begins with a series of parameterized single-qubit rotation gates: `X`, `Y`, and `Z` gates.\n",
        "   - For example, qubit `(0, 0)` has `X^x0`, `Y^x1`, and `Z^x2`, where `x0`, `x1`, and `x2` are parameters. These rotations are tunable, allowing the model to adjust the initial state of each qubit based on the input data.\n",
        "   - These parameterized rotations allow each qubit’s state to be transformed independently, setting up the qubits for further interaction.\n",
        "\n",
        "2. **Two-Qubit Controlled Gates (CNOTs)**:\n",
        "   - After the single-qubit operations, controlled gates (specifically CNOT gates) are applied between neighboring qubits.\n",
        "   - For instance:\n",
        "     - The CNOT gate between qubits `(0, 0)` and `(0, 1)` has `(0, 0)` as the control and `(0, 1)` as the target.\n",
        "     - Similarly, CNOT gates are placed between pairs `(0, 2)` and `(0, 3)`, `(0, 4)` and `(0, 5)`, and `(0, 6)` and `(0, 7)`.\n",
        "   - These CNOT gates create entanglement between neighboring qubits, allowing the qubits to share information and interact in ways that are crucial for feature extraction.\n",
        "\n",
        "3. **Additional Single-Qubit Parameterized Gates**:\n",
        "   - Following the CNOT gates, each qubit has another series of parameterized rotations (`X`, `Y`, `Z`), with negative exponents for some gates, such as `X^-x0`, `Y^-x1`, and `Z^-x2`.\n",
        "   - These additional single-qubit operations can either refine or partially undo the initial transformations on each qubit. This selective resetting is used to control the qubit states after the interaction in the CNOT gates, effectively \"pooling\" information by preserving only certain aspects of each qubit’s transformation.\n",
        "\n",
        "4. **Pooling Structure**:\n",
        "   - The pooling structure of this circuit becomes evident through the combination of entangling (CNOT) gates and selective single-qubit transformations.\n",
        "   - By entangling pairs of qubits and then applying inverse transformations on some qubits, the circuit is able to selectively reset certain qubits while keeping entangled information on others. This operation effectively reduces the dimensionality of the data, as some qubits are \"pooled\" or \"reset\" to a simplified state.\n",
        "\n",
        "***Purpose of the Circuit in QCNN***\n",
        "\n",
        "This circuit layer is specifically designed for the pooling stage of a QCNN, which serves to reduce the number of qubits while preserving essential information. Here’s a breakdown of how it achieves this:\n",
        "\n",
        "- **Feature Extraction via Entanglement**:\n",
        "  - The CNOT gates entangle pairs of qubits, allowing complex patterns and relationships in the quantum state to be captured. This process is akin to how convolution layers in classical CNNs capture spatial features through filters.\n",
        "  \n",
        "- **Dimensionality Reduction via Selective Reset**:\n",
        "  - After the entanglement step, the circuit selectively applies inverse transformations on certain qubits, which helps reset or reduce the information stored in them. This selective reset retains relevant features in specific qubits, reducing the overall complexity of the data.\n",
        "  - By only keeping the essential information in fewer qubits, the circuit performs a pooling operation, reducing the dimensionality of the data in a way that retains critical information for further processing.\n",
        "\n",
        "- **Learnability through Parameterized Gates**:\n",
        "  - Each gate in the circuit has a parameter, making this layer highly adaptable. During training, these parameters can be optimized to learn the best transformations for capturing and retaining the most relevant features.\n",
        "  - The learnable parameters allow the QCNN model to adapt to different quantum data inputs, making it more flexible and powerful for classification or other machine learning tasks.\n",
        "\n",
        "***Summary***\n",
        "\n",
        "This circuit is a quantum pooling layer for a QCNN, structured as follows:\n",
        "\n",
        "- **Initial Parameterized Rotations**: Each qubit undergoes single-qubit rotations (X, Y, Z) with tunable parameters.\n",
        "- **Entangling (CNOT) Gates**: CNOT gates between qubit pairs create entanglement, capturing relationships between neighboring qubits.\n",
        "- **Selective Inverse Rotations**: Inverse single-qubit rotations selectively reset certain qubits, performing dimensionality reduction by preserving key information in a subset of qubits.\n",
        "\n",
        "This quantum pooling circuit effectively reduces the complexity of the quantum state while preserving important features, allowing the QCNN to process quantum data in a structured and efficient way for downstream tasks."
      ],
      "metadata": {
        "id": "aWlENzp_1kk4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23VcPLT45Lg7"
      },
      "source": [
        "## Model definition\n",
        "\n",
        "Now use the defined layers to construct a purely quantum CNN. Start with eight qubits, pool down to one, then measure $\\langle \\hat{Z} \\rangle$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzEsY6-n5NR0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def create_model_circuit(qubits):\n",
        "    \"\"\"Create sequence of alternating convolution and pooling operators\n",
        "    which gradually shrink over time.\"\"\"\n",
        "    model_circuit = cirq.Circuit()\n",
        "    symbols = sympy.symbols('qconv0:63')\n",
        "    # Cirq uses sympy.Symbols to map learnable variables. TensorFlow Quantum\n",
        "    # scans incoming circuits and replaces these with TensorFlow variables.\n",
        "    model_circuit += quantum_conv_circuit(qubits, symbols[0:15])\n",
        "    model_circuit += quantum_pool_circuit(qubits[:4], qubits[4:],\n",
        "                                          symbols[15:21])\n",
        "    model_circuit += quantum_conv_circuit(qubits[4:], symbols[21:36])\n",
        "    model_circuit += quantum_pool_circuit(qubits[4:6], qubits[6:],\n",
        "                                          symbols[36:42])\n",
        "    model_circuit += quantum_conv_circuit(qubits[6:], symbols[42:57])\n",
        "    model_circuit += quantum_pool_circuit([qubits[6]], [qubits[7]],\n",
        "                                          symbols[57:63])\n",
        "    return model_circuit\n",
        "\n",
        "\n",
        "# Create our qubits and readout operators in Cirq.\n",
        "cluster_state_bits = cirq.GridQubit.rect(1, 8)\n",
        "readout_operators = cirq.Z(cluster_state_bits[-1])\n",
        "\n",
        "# Build a sequential model enacting the logic in 1.3 of this notebook.\n",
        "# Here you are making the static cluster state prep as a part of the AddCircuit and the\n",
        "# \"quantum datapoints\" are coming in the form of excitation\n",
        "excitation_input = tf.keras.Input(shape=(), dtype=tf.dtypes.string)\n",
        "cluster_state = tfq.layers.AddCircuit()(\n",
        "    excitation_input, prepend=cluster_state_circuit(cluster_state_bits))\n",
        "\n",
        "quantum_model = tfq.layers.PQC(create_model_circuit(cluster_state_bits),\n",
        "                               readout_operators)(cluster_state)\n",
        "\n",
        "qcnn_model = tf.keras.Model(inputs=[excitation_input], outputs=[quantum_model])\n",
        "\n",
        "# Show the keras plot of the model\n",
        "tf.keras.utils.plot_model(qcnn_model,\n",
        "                          show_shapes=True,\n",
        "                          show_layer_names=False,\n",
        "                          dpi=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows a simple *quantum-classical hybrid model architecture* built using TensorFlow Quantum. It consists of three main layers: an `InputLayer`, an `AddCircuit` layer, and a `PQC` (Parameterized Quantum Circuit) layer. Here's an explanation of each layer and its role in the model:\n",
        "\n",
        "***1. InputLayer***\n",
        "\n",
        "- **Description**: The `InputLayer` is the starting point of the model, defining the shape and type of data that the model will accept.\n",
        "- **Input Shape**: `[(None,)]` indicates that the model can accept a batch of quantum circuits as input. `None` represents the batch size, which is flexible and can be determined during runtime.\n",
        "- **Output Shape**: `[(None,)]` means that the input is passed through unchanged, preparing it for the next layer.\n",
        "- **Purpose**: This layer takes in quantum data (represented as circuit tensors) and provides a structured input for further quantum processing.\n",
        "\n",
        "***2. AddCircuit Layer***\n",
        "\n",
        "- **Description**: The `AddCircuit` layer is a layer in TensorFlow Quantum that allows you to append or prepend a predefined quantum circuit to each input circuit.\n",
        "- **Input Shape**: `None`, indicating that the input here is a batch of circuits.\n",
        "- **Output Shape**: `[(None,)]`, meaning that the output is still a batch of circuits with the added circuit embedded.\n",
        "- **Purpose**: This layer is used to apply a fixed quantum circuit (such as a cluster state preparation or some other initial circuit) to each input circuit. This fixed circuit serves as a foundational structure or initial state for further quantum operations. For example, in a quantum convolutional neural network (QCNN), it might be used to prepare a specific cluster state.\n",
        "\n",
        "***3. PQC (Parameterized Quantum Circuit) Layer***\n",
        "\n",
        "- **Description**: The `PQC` layer in TensorFlow Quantum is a layer that takes a parameterized quantum circuit and outputs the expectation value of an observable, such as the Pauli-Z operator. This layer enables the model to perform a final measurement on the quantum circuit and produce a classical output.\n",
        "- **Input Shape**: `None`, as it accepts a batch of circuits (now modified by the `AddCircuit` layer).\n",
        "- **Output Shape**: `[(None, 1)]`, indicating that the output is a batch of single scalar values (one for each circuit).\n",
        "- **Purpose**: This layer performs the final inference step by measuring the expectation value of a chosen observable (like ⟨Z⟩). The result of this measurement is used as the output of the model, which is typically a single value indicating the classification or prediction result.\n",
        "\n",
        "***Overall Model Purpose***\n",
        "\n",
        "This model architecture represents a straightforward quantum-classical hybrid model, where the input is a quantum circuit, and the output is a single classical scalar value. Here’s how it functions in the context of a quantum machine learning task:\n",
        "\n",
        "1. **Input Preparation**: The `InputLayer` accepts quantum circuits as inputs.\n",
        "2. **Embedding a Fixed Circuit**: The `AddCircuit` layer appends or prepends a fixed quantum circuit (such as a cluster state preparation or quantum feature extraction circuit) to each input, ensuring each circuit starts from a standardized initial state.\n",
        "3. **Quantum Inference and Measurement**: The `PQC` layer performs the final measurement on each circuit, producing a classical output. This output can be used for tasks like binary classification, where the model determines whether a quantum state belongs to one of two categories.\n",
        "\n",
        "This architecture is suitable for quantum machine learning tasks where quantum data is processed through a fixed initial state, followed by parameterized operations that allow for flexible learning, and finally measured to produce a classical prediction. The simplicity of this model makes it efficient for tasks that require a hybrid quantum-classical approach."
      ],
      "metadata": {
        "id": "APEvI6RB1-as"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jqTEe5VSbug"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Train the model over the full batch to simplify this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TFkAm1sQZEN",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Generate some training data.\n",
        "train_excitations, train_labels, test_excitations, test_labels = generate_data(\n",
        "    cluster_state_bits)\n",
        "\n",
        "\n",
        "# Custom accuracy metric.\n",
        "@tf.function\n",
        "def custom_accuracy(y_true, y_pred):\n",
        "    y_true = tf.squeeze(y_true)\n",
        "    y_pred = tf.map_fn(lambda x: 1.0 if x >= 0 else -1.0, y_pred)\n",
        "    return tf.keras.backend.mean(tf.keras.backend.equal(y_true, y_pred))\n",
        "\n",
        "\n",
        "qcnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.02),\n",
        "                   loss=tf.losses.mse,\n",
        "                   metrics=[custom_accuracy])\n",
        "\n",
        "history = qcnn_model.fit(x=train_excitations,\n",
        "                         y=train_labels,\n",
        "                         batch_size=16,\n",
        "                         epochs=25,\n",
        "                         verbose=1,\n",
        "                         validation_data=(test_excitations, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This output shows the training and validation results for the 25th (final) epoch of a quantum-classical hybrid model training in TensorFlow. Let's break down each component:\n",
        "\n",
        "1. **Epoch 25/25**:\n",
        "   - This indicates that the model is currently at the 25th and final epoch of training. An epoch is one full cycle through the entire training dataset, and the model was set to train for a total of 25 epochs.\n",
        "\n",
        "2. **7/7 [==============================] - 1s 132ms/step**:\n",
        "   - **7/7**: This shows that there are 7 batches in each epoch, and all 7 batches have been processed for this epoch.\n",
        "   - **1s**: The total time taken to complete this epoch was approximately 1 second.\n",
        "   - **132ms/step**: This indicates the average time per batch (step), which is 132 milliseconds.\n",
        "\n",
        "3. **Loss and Accuracy Metrics**:\n",
        "   - **loss: 0.5364**: This is the training loss at the end of the 25th epoch, calculated on the training dataset. A lower loss generally indicates better performance in terms of the model’s fit to the training data.\n",
        "   - **custom_accuracy: 0.8929**: This is the training accuracy for the 25th epoch, reported using a custom accuracy metric. It shows that the model achieved an accuracy of 89.29% on the training data in this epoch.\n",
        "\n",
        "4. **Validation Loss and Accuracy Metrics**:\n",
        "   - **val_loss: 0.5856**: This is the validation loss at the end of the 25th epoch, calculated on the validation dataset. It indicates how well the model is performing on unseen data. A higher validation loss compared to the training loss may suggest slight overfitting, but the difference here is minimal.\n",
        "   - **val_custom_accuracy: 0.8958**: This is the validation accuracy using the custom accuracy metric, calculated on the validation dataset. The model achieved an accuracy of 89.58% on the validation data in this epoch, which is comparable to the training accuracy, indicating that the model generalizes well.\n",
        "\n",
        "***Summary***\n",
        "\n",
        "At the end of 25 epochs:\n",
        "- The model has a **training loss of 0.5364** and a **training accuracy of 89.29%**.\n",
        "- On the validation data, the model achieved a **validation loss of 0.5856** and a **validation accuracy of 89.58%**.\n",
        "\n",
        "These metrics suggest that the model has learned to classify or predict well, with similar performance on both training and validation data, indicating that it is not overfitting and generalizes effectively to unseen data."
      ],
      "metadata": {
        "id": "GlMTL1iw2gbP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tiCJOb5Qzcr",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'][1:], label='Training')\n",
        "plt.plot(history.history['val_loss'][1:], label='Validation')\n",
        "plt.title('Training a Quantum CNN to Detect Excited Cluster States')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot shows the loss values for both the training and validation datasets over the course of training epochs for a Quantum Convolutional Neural Network (QCNN) model. The model is being trained to detect \"excited\" cluster states, and the loss values are used as a measure of how well the model fits the data. Here’s a detailed breakdown:\n",
        "\n",
        "***Plot Components***\n",
        "\n",
        "1. **Axes**:\n",
        "   - **X-axis (Epochs)**: This represents the training epochs, ranging from 0 to 25. Each epoch corresponds to one full pass through the training dataset.\n",
        "   - **Y-axis (Loss)**: This represents the loss value. Loss is a measure of the model’s error; lower loss indicates better model performance on the respective dataset (training or validation).\n",
        "\n",
        "2. **Curves**:\n",
        "   - **Blue Line (Training Loss)**: This line shows the loss on the training dataset over each epoch.\n",
        "   - **Orange Line (Validation Loss)**: This line shows the loss on the validation dataset, which is an unseen portion of data used to assess how well the model generalizes.\n",
        "\n",
        "***Observations***\n",
        "\n",
        "1. **Decreasing Loss**:\n",
        "   - Both the training and validation loss decrease over time, indicating that the model is learning and improving its performance as training progresses.\n",
        "   - The training loss (blue line) decreases steadily, showing that the model is gradually fitting the training data better with each epoch.\n",
        "   - The validation loss (orange line) also decreases, but it fluctuates a bit more than the training loss, which is typical as validation data helps assess how well the model generalizes to unseen data.\n",
        "\n",
        "2. **Convergence**:\n",
        "   - By the end of training (around 25 epochs), both the training and validation loss values converge close to each other, indicating that the model performs similarly on both datasets.\n",
        "   - The fact that the validation loss is close to the training loss suggests that the model is not overfitting. Overfitting would typically show a large gap between training and validation losses, with training loss decreasing while validation loss remains high or starts to increase.\n",
        "\n",
        "3. **Generalization**:\n",
        "   - The validation loss remains consistently close to the training loss, which is a good sign of generalization. This indicates that the model can generalize its learning to new data (validation data in this case) and is not just memorizing the training data.\n",
        "\n",
        "***Summary***\n",
        "\n",
        "The plot demonstrates that the Quantum CNN model is learning effectively, as indicated by the decreasing training and validation losses. Both losses converge to similar values by the end of training, suggesting that the model is well-regularized and generalizes well to unseen data. This is a positive indication that the model has effectively learned to detect excited cluster states without overfitting."
      ],
      "metadata": {
        "id": "aTjpUBFs20KD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyrkcEReQ5Bc"
      },
      "source": [
        "# Hybrid models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You don't have to go from eight qubits to one qubit using quantum convolution—you could have done one or two rounds of quantum convolution and fed the results into a classical neural network. This section explores quantum-classical hybrid models."
      ],
      "metadata": {
        "id": "Xg-B5JmIw295"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hybrid model with a single quantum filter"
      ],
      "metadata": {
        "id": "Ar_-2OmPxEhr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2tOK22t7Kjm"
      },
      "source": [
        "Apply one layer of quantum convolution, reading out $\\langle \\hat{Z}_n \\rangle$ on all bits, followed by a densely-connected neural network.\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/images/qcnn_5.png?raw=1\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKXuOApgWYFa"
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut-U1hBkQ8Fs",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# 1-local operators to read out\n",
        "readouts = [cirq.Z(bit) for bit in cluster_state_bits[4:]]\n",
        "\n",
        "\n",
        "def multi_readout_model_circuit(qubits):\n",
        "    \"\"\"Make a model circuit with less quantum pool and conv operations.\"\"\"\n",
        "    model_circuit = cirq.Circuit()\n",
        "    symbols = sympy.symbols('qconv0:21')\n",
        "    model_circuit += quantum_conv_circuit(qubits, symbols[0:15])\n",
        "    model_circuit += quantum_pool_circuit(qubits[:4], qubits[4:],\n",
        "                                          symbols[15:21])\n",
        "    return model_circuit\n",
        "\n",
        "\n",
        "# Build a model enacting the logic in 2.1 of this notebook.\n",
        "excitation_input_dual = tf.keras.Input(shape=(), dtype=tf.dtypes.string)\n",
        "\n",
        "cluster_state_dual = tfq.layers.AddCircuit()(\n",
        "    excitation_input_dual, prepend=cluster_state_circuit(cluster_state_bits))\n",
        "\n",
        "quantum_model_dual = tfq.layers.PQC(\n",
        "    multi_readout_model_circuit(cluster_state_bits),\n",
        "    readouts)(cluster_state_dual)\n",
        "\n",
        "d1_dual = tf.keras.layers.Dense(8)(quantum_model_dual)\n",
        "\n",
        "d2_dual = tf.keras.layers.Dense(1)(d1_dual)\n",
        "\n",
        "hybrid_model = tf.keras.Model(inputs=[excitation_input_dual], outputs=[d2_dual])\n",
        "\n",
        "# Display the model architecture\n",
        "tf.keras.utils.plot_model(hybrid_model,\n",
        "                          show_shapes=True,\n",
        "                          show_layer_names=False,\n",
        "                          dpi=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This image shows a *quantum-classical hybrid neural network architecture* that combines quantum processing layers with classical fully connected (dense) layers. The architecture includes an `InputLayer`, an `AddCircuit` layer, a `PQC` (Parameterized Quantum Circuit) layer, and two dense (fully connected) layers. Here’s a detailed breakdown of each layer and its role in the model:\n",
        "\n",
        "***1. InputLayer***\n",
        "\n",
        "- **Description**: This is the starting layer of the model, which defines the shape and type of data the model will receive.\n",
        "- **Input Shape**: `[(None,)]`, indicating that the input is a batch of quantum circuits, where `None` represents a flexible batch size.\n",
        "- **Output Shape**: `[(None,)]`, meaning that the data shape is unchanged as it passes to the next layer.\n",
        "- **Purpose**: This layer accepts quantum circuit inputs, which will be processed by quantum components in subsequent layers.\n",
        "\n",
        "***2. AddCircuit Layer***\n",
        "\n",
        "- **Description**: This layer appends or prepends a predefined quantum circuit to each input circuit. It is commonly used in TensorFlow Quantum to embed a fixed quantum operation to prepare a specific state.\n",
        "- **Input Shape**: `None`, as the input is a batch of circuits.\n",
        "- **Output Shape**: `[(None,)]`, meaning the output remains a batch of circuits, now with the predefined circuit added.\n",
        "- **Purpose**: This layer could be used to add a cluster state or some other standard quantum state as a base for further quantum transformations in the model. This provides a consistent starting state across all inputs.\n",
        "\n",
        "***3. PQC (Parameterized Quantum Circuit) Layer***\n",
        "\n",
        "- **Description**: The PQC layer in TensorFlow Quantum applies a parameterized quantum circuit to each input and measures specific observables to produce a classical output.\n",
        "- **Input Shape**: `None`, as it receives a batch of quantum circuits from the `AddCircuit` layer.\n",
        "- **Output Shape**: `[(None, 4)]`, indicating that the layer outputs a batch of 4-dimensional vectors, where each dimension is a measured expectation value from the quantum circuit.\n",
        "- **Purpose**: This layer performs the quantum computation and outputs classical values (expectation values) that summarize the quantum state in a way that can be used by classical layers. These 4-dimensional outputs serve as features for the classical part of the model.\n",
        "\n",
        "***4. First Dense Layer***\n",
        "\n",
        "- **Description**: This is a classical fully connected (dense) layer that processes the 4-dimensional outputs from the PQC layer.\n",
        "- **Input Shape**: `[(None, 4)]`, representing the 4-dimensional vector output from each quantum circuit in the batch.\n",
        "- **Output Shape**: `[(None, 8)]`, meaning that this layer transforms the input into an 8-dimensional vector for each sample.\n",
        "- **Purpose**: This dense layer acts as a feature transformation layer, allowing the model to learn relationships within the 4-dimensional outputs from the PQC layer and expand the representation to 8 dimensions.\n",
        "\n",
        "***5. Second Dense Layer (Output Layer)***\n",
        "\n",
        "- **Description**: This is another fully connected layer that reduces the dimensionality of the output to a single value, making it suitable for binary classification or regression.\n",
        "- **Input Shape**: `[(None, 8)]`, the 8-dimensional output from the previous dense layer.\n",
        "- **Output Shape**: `[(None, 1)]`, providing a single output value for each sample in the batch.\n",
        "- **Purpose**: This layer produces the final output, which could represent a binary classification (e.g., detecting an \"excited\" state vs. a \"non-excited\" state) or a regression output, depending on the task.\n",
        "\n",
        "***Overall Model Purpose***\n",
        "\n",
        "This hybrid model structure integrates quantum computation with classical processing, taking advantage of both quantum feature extraction and classical neural network layers. Here’s how it functions in the context of a quantum machine learning task:\n",
        "\n",
        "1. **Quantum Processing**: The `AddCircuit` and `PQC` layers handle the quantum part of the model. The `AddCircuit` layer embeds a fixed quantum circuit as a starting point, and the `PQC` layer applies a parameterized quantum circuit to extract features from the quantum data, outputting classical values.\n",
        "  \n",
        "2. **Classical Processing**: The dense layers process the classical output from the PQC layer, enabling the model to learn complex relationships and generate predictions. These layers handle feature transformation and final output.\n",
        "\n",
        "This architecture is ideal for tasks where quantum data needs to be processed, and classical layers can refine the quantum-derived features to make a final prediction, such as detecting specific states or classifying quantum data. The model combines the strengths of both quantum and classical processing, making it powerful and adaptable for quantum machine learning applications."
      ],
      "metadata": {
        "id": "-WfeNuiv3LWm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDqoLZJuWcgH"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyYw9kYIRCE7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "hybrid_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.02),\n",
        "                     loss=tf.losses.mse,\n",
        "                     metrics=[custom_accuracy])\n",
        "\n",
        "hybrid_history = hybrid_model.fit(x=train_excitations,\n",
        "                                  y=train_labels,\n",
        "                                  batch_size=16,\n",
        "                                  epochs=25,\n",
        "                                  verbose=1,\n",
        "                                  validation_data=(test_excitations,\n",
        "                                                   test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This output shows the training and validation results for the 25th (final) epoch of a model's training process in TensorFlow. Here’s a breakdown of each component:\n",
        "\n",
        "1. **Epoch 25/25**:\n",
        "   - This indicates that the model is currently at the 25th and final epoch of training. An epoch is one full pass through the entire training dataset. In this case, the model was set to train for a total of 25 epochs.\n",
        "\n",
        "2. **7/7 [==============================] - 1s 82ms/step**:\n",
        "   - **7/7**: This shows that there are 7 batches in each epoch, and all 7 batches have been processed for this epoch.\n",
        "   - **1s**: The total time taken to complete this epoch was approximately 1 second.\n",
        "   - **82ms/step**: This is the average time per batch (step), which is 82 milliseconds.\n",
        "\n",
        "3. **Loss and Accuracy Metrics**:\n",
        "   - **loss: 0.2064**: This is the training loss at the end of the 25th epoch, calculated on the training dataset. A lower loss generally indicates better performance in terms of the model’s fit to the training data.\n",
        "   - **custom_accuracy: 0.9732**: This is the training accuracy for the 25th epoch, reported using a custom accuracy metric. It shows that the model achieved an accuracy of 97.32% on the training data in this epoch.\n",
        "\n",
        "4. **Validation Loss and Accuracy Metrics**:\n",
        "   - **val_loss: 0.2517**: This is the validation loss at the end of the 25th epoch, calculated on the validation dataset. The validation loss is slightly higher than the training loss, which is typical and often indicates that the model is generalizing well. However, if the validation loss were much higher, it could suggest overfitting.\n",
        "   - **val_custom_accuracy: 0.9583**: This is the validation accuracy, calculated on the validation dataset using the same custom accuracy metric. The model achieved an accuracy of 95.83% on the validation data, which is close to the training accuracy, indicating good generalization.\n",
        "\n",
        "***Summary***\n",
        "\n",
        "At the end of the 25th epoch:\n",
        "- The model has a **training loss of 0.2064** and a **training accuracy of 97.32%**.\n",
        "- On the validation data, the model achieved a **validation loss of 0.2517** and a **validation accuracy of 95.83%**.\n",
        "\n",
        "These results indicate that the model is performing well:\n",
        "- **High accuracy** on both training and validation datasets suggests that the model is effectively learning the patterns in the data.\n",
        "- **Low loss values** for both training and validation datasets indicate that the model’s predictions are close to the actual labels, and the model is well-optimized.\n",
        "- **Comparable training and validation accuracy** suggests that the model is generalizing well to new data and is not overfitting.\n",
        "\n",
        "Overall, this output indicates successful training with strong model performance on both training and validation datasets."
      ],
      "metadata": {
        "id": "ts-lsIe24jYd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL3jhGiBRJHt",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['val_custom_accuracy'], label='QCNN')\n",
        "plt.plot(hybrid_history.history['val_custom_accuracy'], label='Hybrid CNN')\n",
        "plt.title('Quantum vs Hybrid CNN performance')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCNiNvheRNzq"
      },
      "source": [
        "This plot compares the **validation accuracy** of two different models—a Quantum Convolutional Neural Network (QCNN) and a Hybrid Convolutional Neural Network (Hybrid CNN)—over 25 training epochs. Here’s a breakdown of the key components and insights from the plot:\n",
        "\n",
        "***Plot Components***\n",
        "\n",
        "1. **Axes**:\n",
        "   - **X-axis (Epochs)**: Represents the number of training epochs, ranging from 0 to 25. Each epoch corresponds to one complete pass through the training data.\n",
        "   - **Y-axis (Validation Accuracy)**: Represents the accuracy of each model on the validation dataset. Higher accuracy indicates better model performance on unseen data.\n",
        "\n",
        "2. **Curves**:\n",
        "   - **Blue Line (QCNN)**: This line represents the validation accuracy of the Quantum Convolutional Neural Network (QCNN) over time.\n",
        "   - **Orange Line (Hybrid CNN)**: This line shows the validation accuracy of the Hybrid CNN, which is a hybrid quantum-classical model, over time.\n",
        "\n",
        "***Observations***\n",
        "\n",
        "1. **Initial Learning Rate**:\n",
        "   - At the beginning (epochs 0-5), both models start with relatively low accuracy, but they quickly improve over the initial epochs. The Hybrid CNN (orange line) shows a steep increase in accuracy, outperforming the QCNN (blue line) from the start.\n",
        "   - The Hybrid CNN reaches a high accuracy level by around epoch 5, suggesting that it may have learned the task more quickly than the QCNN.\n",
        "\n",
        "2. **Stabilization and Performance Comparison**:\n",
        "   - After about 5 epochs, both models begin to stabilize, with the QCNN’s accuracy leveling off around 85-90% and the Hybrid CNN’s accuracy leveling off around 95-100%.\n",
        "   - The Hybrid CNN consistently outperforms the QCNN across all epochs. This indicates that the hybrid model may be more effective at capturing and processing the features needed for accurate predictions on this dataset.\n",
        "\n",
        "3. **Performance Consistency**:\n",
        "   - The Hybrid CNN maintains high accuracy with minimal fluctuations after it reaches stability, consistently achieving around 95-100% accuracy on the validation set.\n",
        "   - The QCNN shows minor fluctuations in accuracy across the later epochs, indicating a slightly less stable performance. Its accuracy hovers around 85-90%, suggesting it may be limited in its capacity to fully capture the features needed for peak performance compared to the hybrid model.\n",
        "\n",
        "***Insights***\n",
        "\n",
        "- **Hybrid CNN Advantage**: The Hybrid CNN model achieves better validation accuracy and stabilizes at a higher accuracy level than the QCNN. This could be due to the classical layers in the Hybrid CNN, which may provide additional processing power for feature extraction and generalization, combining both quantum and classical strengths.\n",
        "  \n",
        "- **QCNN Limitations**: While the QCNN performs well, achieving up to 90% accuracy, it doesn’t reach the same level of accuracy as the Hybrid CNN. This could suggest that, for this specific dataset and task, the pure quantum approach may be limited in its expressiveness or generalization capabilities compared to a hybrid approach.\n",
        "\n",
        "- **Potential Overfitting Consideration**: The Hybrid CNN’s near-100% accuracy could imply a risk of overfitting if the validation dataset is not sufficiently large or diverse. However, if the validation dataset is representative of the target data, this high accuracy suggests that the Hybrid CNN is very effective for this task.\n",
        "\n",
        "***Summary***\n",
        "\n",
        "This plot demonstrates that the Hybrid CNN outperforms the QCNN in terms of validation accuracy, achieving higher and more stable performance across 25 epochs. The Hybrid CNN benefits from both quantum and classical processing, leading to superior feature extraction and generalization. This result highlights the potential of hybrid quantum-classical models to perform better than purely quantum models in certain machine learning tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVUtWLZnRRDE"
      },
      "source": [
        "## Hybrid convolution with multiple quantum filters\n",
        "\n",
        "Now let's try an architecture that uses multiple quantum convolutions and a classical neural network to combine them.\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/images/qcnn_6.png?raw=1\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldo_m5P3YBV7"
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3TkNVm9RTBj",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "excitation_input_multi = tf.keras.Input(shape=(), dtype=tf.dtypes.string)\n",
        "\n",
        "cluster_state_multi = tfq.layers.AddCircuit()(\n",
        "    excitation_input_multi, prepend=cluster_state_circuit(cluster_state_bits))\n",
        "\n",
        "# apply 3 different filters and measure expectation values\n",
        "\n",
        "quantum_model_multi1 = tfq.layers.PQC(\n",
        "    multi_readout_model_circuit(cluster_state_bits),\n",
        "    readouts)(cluster_state_multi)\n",
        "\n",
        "quantum_model_multi2 = tfq.layers.PQC(\n",
        "    multi_readout_model_circuit(cluster_state_bits),\n",
        "    readouts)(cluster_state_multi)\n",
        "\n",
        "quantum_model_multi3 = tfq.layers.PQC(\n",
        "    multi_readout_model_circuit(cluster_state_bits),\n",
        "    readouts)(cluster_state_multi)\n",
        "\n",
        "# concatenate outputs and feed into a small classical NN\n",
        "concat_out = tf.keras.layers.concatenate(\n",
        "    [quantum_model_multi1, quantum_model_multi2, quantum_model_multi3])\n",
        "\n",
        "dense_1 = tf.keras.layers.Dense(8)(concat_out)\n",
        "\n",
        "dense_2 = tf.keras.layers.Dense(1)(dense_1)\n",
        "\n",
        "multi_qconv_model = tf.keras.Model(inputs=[excitation_input_multi],\n",
        "                                   outputs=[dense_2])\n",
        "\n",
        "# Display the model architecture\n",
        "tf.keras.utils.plot_model(multi_qconv_model,\n",
        "                          show_shapes=True,\n",
        "                          show_layer_names=True,\n",
        "                          dpi=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This diagram represents a more complex quantum-classical hybrid model architecture, where multiple quantum processing paths are combined before feeding into classical layers. Here’s a breakdown of each component and its role in the model:\n",
        "\n",
        "***1. Input Layer (`input_3`)***\n",
        "   - **Type**: `InputLayer`\n",
        "   - **Input Shape**: `[(None,)]`\n",
        "   - **Output Shape**: `[(None,)]`\n",
        "   - **Description**: This is the input layer for the model, which accepts a batch of quantum circuits (represented by TensorFlow Quantum’s circuit tensor format). `None` represents a flexible batch size.\n",
        "\n",
        "***2. Add Circuit Layer (`add_circuit_5`)***\n",
        "   - **Type**: `AddCircuit`\n",
        "   - **Input Shape**: `None`\n",
        "   - **Output Shape**: `[(None,)]`\n",
        "   - **Description**: This layer appends a predefined quantum circuit to each input circuit. This circuit could be a specific initial state (like a cluster state) or a fixed quantum transformation that will be applied to all inputs as a starting point.\n",
        "\n",
        "***3. PQC Layers (`pqc_2`, `pqc_3`, `pqc_4`)***\n",
        "   - **Type**: `PQC` (Parameterized Quantum Circuit)\n",
        "   - **Input Shape**: `None`\n",
        "   - **Output Shape**: `[(None, 4)]` for each `PQC` layer\n",
        "   - **Description**: These PQC layers apply parameterized quantum circuits on the input data and measure the expectation values of observables, producing classical outputs. Each PQC layer outputs a 4-dimensional vector (presumably from four different measurements or observables in the quantum circuit).\n",
        "   - **Purpose**: These three parallel PQC layers allow the model to extract multiple quantum features from the input circuit. Each PQC layer might represent a different set of parameterized quantum operations, capturing various aspects of the quantum state.\n",
        "\n",
        "***4. Concatenate Layer***\n",
        "   - **Type**: `Concatenate`\n",
        "   - **Input Shape**: `[(None, 4), (None, 4), (None, 4)]`\n",
        "   - **Output Shape**: `[(None, 12)]`\n",
        "   - **Description**: This layer concatenates the outputs from the three PQC layers, resulting in a 12-dimensional vector for each sample in the batch.\n",
        "   - **Purpose**: By combining the features from all three PQC layers, the model aggregates different quantum feature representations, allowing for a richer feature set to be processed by the classical part of the model.\n",
        "\n",
        "***5. First Dense Layer (`dense_2`)**\n",
        "   - **Type**: `Dense`\n",
        "   - **Input Shape**: `[(None, 12)]`\n",
        "   - **Output Shape**: `[(None, 8)]`\n",
        "   - **Description**: This dense layer receives the 12-dimensional concatenated vector and reduces it to an 8-dimensional representation.\n",
        "   - **Purpose**: This layer acts as a feature transformation layer, enabling the model to learn patterns within the combined quantum features. It helps compress the information while retaining essential features.\n",
        "\n",
        "***6. Second Dense Layer (`dense_3`)***\n",
        "   - **Type**: `Dense`\n",
        "   - **Input Shape**: `[(None, 8)]`\n",
        "   - **Output Shape**: `[(None, 1)]`\n",
        "   - **Description**: This is the final dense layer in the model, which reduces the 8-dimensional vector to a single output value for each sample.\n",
        "   - **Purpose**: This output layer is designed for binary classification (with a single neuron output), where the output value can be interpreted as a probability score for one of two classes. It could also be used for regression tasks if the output is continuous.\n",
        "\n",
        "***Overall Model Workflow***\n",
        "\n",
        "1. **Input Preparation**: The input layer receives quantum circuits as inputs.\n",
        "2. **Circuit Addition**: The `AddCircuit` layer adds a predefined circuit, providing a consistent starting point for all samples.\n",
        "3. **Quantum Feature Extraction**: Three parallel PQC layers each apply different parameterized quantum circuits, measuring specific observables to extract a 4-dimensional feature vector from each circuit.\n",
        "4. **Feature Aggregation**: The `Concatenate` layer combines the outputs of the three PQC layers into a single 12-dimensional vector, integrating diverse quantum features.\n",
        "5. **Classical Processing**: The concatenated quantum features pass through two dense layers, where the model learns relationships among the features and produces a single output for each input sample.\n",
        "\n",
        "***Purpose of This Model Architecture***\n",
        "\n",
        "This model structure is well-suited for quantum machine learning tasks where multiple quantum measurements or features are needed to capture the complexity of the data. By using parallel PQC layers, the model can learn a rich representation of the quantum state. The classical dense layers then process these quantum-derived features to make final predictions. This architecture is powerful for tasks requiring detailed quantum feature extraction combined with classical learning techniques, such as classification or regression."
      ],
      "metadata": {
        "id": "kP7GxmGy5UoN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eNhDWwKY9N4"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suRvxcAKRZK6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "multi_qconv_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.02),\n",
        "    loss=tf.losses.mse,\n",
        "    metrics=[custom_accuracy])\n",
        "\n",
        "multi_qconv_history = multi_qconv_model.fit(x=train_excitations,\n",
        "                                            y=train_labels,\n",
        "                                            batch_size=16,\n",
        "                                            epochs=25,\n",
        "                                            verbose=1,\n",
        "                                            validation_data=(test_excitations,\n",
        "                                                             test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This output shows the results of the 25th and final epoch of training for a quantum-classical hybrid model. Here’s a detailed explanation of each component:\n",
        "\n",
        "1. **Epoch 25/25**:\n",
        "   - This indicates that the model is on the 25th and last epoch of training. An epoch is one complete pass through the training dataset, and the model was set to train for a total of 25 epochs.\n",
        "\n",
        "2. **7/7 [==============================] - 1s 211ms/step**:\n",
        "   - **7/7**: This shows that there are 7 batches of data in each epoch, and all 7 batches have been processed for this epoch.\n",
        "   - **1s**: The total time taken to complete this epoch was approximately 1 second.\n",
        "   - **211ms/step**: This is the average time taken per batch (step), which is 211 milliseconds.\n",
        "\n",
        "3. **Loss and Accuracy Metrics**:\n",
        "   - **loss: 0.1987**: This is the training loss for the 25th epoch, calculated on the training dataset. A lower loss indicates that the model’s predictions are close to the actual values in the training data. A loss of 0.1987 suggests that the model has learned the patterns in the training data well.\n",
        "   - **custom_accuracy: 0.9643**: This is the training accuracy for the 25th epoch, measured using a custom accuracy metric defined for this model. An accuracy of 0.9643 (or 96.43%) means that the model correctly predicted the training data labels 96.43% of the time, indicating high accuracy on the training dataset.\n",
        "\n",
        "4. **Validation Loss and Accuracy Metrics**:\n",
        "   - **val_loss: 0.2615**: This is the validation loss for the 25th epoch, calculated on the validation dataset. The validation loss is slightly higher than the training loss, which is typical and indicates that the model is slightly less accurate on unseen data compared to training data.\n",
        "   - **val_custom_accuracy: 0.9583**: This is the validation accuracy, also using the custom accuracy metric, calculated on the validation dataset. The model achieved an accuracy of 0.9583 (or 95.83%) on the validation data in this epoch, which is very close to the training accuracy. This suggests that the model generalizes well to unseen data.\n",
        "\n",
        "***Summary***\n",
        "\n",
        "At the end of 25 epochs:\n",
        "- The model achieved a **training loss of 0.1987** and a **training accuracy of 96.43%**.\n",
        "- On the validation data, the model achieved a **validation loss of 0.2615** and a **validation accuracy of 95.83%**.\n",
        "\n",
        "***Insights***\n",
        "\n",
        "- **High Accuracy**: Both training and validation accuracies are high (around 96% for training and 95.8% for validation), indicating that the model is effective at learning the task.\n",
        "- **Low Loss**: The low loss values for both training and validation datasets suggest that the model’s predictions are close to the true values, showing that it has learned the patterns well.\n",
        "- **Generalization**: The training and validation accuracies are close to each other, and the validation loss is only slightly higher than the training loss. This suggests that the model is not overfitting and generalizes well to new data.\n",
        "\n",
        "Overall, this output indicates that the model has trained successfully and is performing well on both the training and validation datasets, showing good generalization and high accuracy."
      ],
      "metadata": {
        "id": "Y4bOBYde6Bs1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6NR7yAQRmOU",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['val_custom_accuracy'][:25], label='QCNN')\n",
        "plt.plot(hybrid_history.history['val_custom_accuracy'][:25], label='Hybrid CNN')\n",
        "plt.plot(multi_qconv_history.history['val_custom_accuracy'][:25],\n",
        "         label='Hybrid CNN \\n Multiple Quantum Filters')\n",
        "plt.title('Quantum vs Hybrid CNN performance')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot compares the **validation accuracy** of three different models across 25 epochs:\n",
        "\n",
        "1. **QCNN (Quantum Convolutional Neural Network)** - Blue line\n",
        "2. **Hybrid CNN** - Orange line\n",
        "3. **Hybrid CNN with Multiple Quantum Filters** - Green line\n",
        "\n",
        "Each line represents the model's validation accuracy over the epochs, providing insight into how each model learns and generalizes on unseen data. Here’s a detailed breakdown of each component and the insights drawn from the plot.\n",
        "\n",
        "***Plot Components***\n",
        "\n",
        "1. **Axes**:\n",
        "   - **X-axis (Epochs)**: Represents the number of training epochs, ranging from 0 to 25. Each epoch corresponds to one complete pass through the training data.\n",
        "   - **Y-axis (Validation Accuracy)**: Represents the accuracy of each model on the validation dataset. Higher accuracy indicates better model performance on unseen data.\n",
        "\n",
        "2. **Lines**:\n",
        "   - **Blue Line (QCNN)**: Represents the validation accuracy of the pure Quantum Convolutional Neural Network (QCNN) model.\n",
        "   - **Orange Line (Hybrid CNN)**: Represents the validation accuracy of the Hybrid CNN model, which combines quantum and classical layers.\n",
        "   - **Green Line (Hybrid CNN with Multiple Quantum Filters)**: Represents the validation accuracy of a Hybrid CNN model with multiple quantum filters, potentially extracting more complex features.\n",
        "\n",
        "***Observations***\n",
        "\n",
        "1. **Initial Training Phase (Epochs 0-5)**:\n",
        "   - The **Hybrid CNN** (orange line) quickly gains high accuracy within the first few epochs, reaching approximately 90% accuracy by epoch 5. This suggests that the hybrid model learns faster and effectively utilizes both quantum and classical components.\n",
        "   - The **QCNN** (blue line) also improves in accuracy but at a slower rate, stabilizing around 85-90% accuracy by epoch 5.\n",
        "   - The **Hybrid CNN with Multiple Quantum Filters** (green line) initially learns quickly, reaching above 90% accuracy by epoch 5. This suggests that using multiple quantum filters may improve the model’s initial feature extraction capabilities.\n",
        "\n",
        "2. **Stabilization and Performance Comparison**:\n",
        "   - The **Hybrid CNN** and **Hybrid CNN with Multiple Quantum Filters** both achieve high accuracy, fluctuating around 95-100% after epoch 5, suggesting they are both effective at generalizing to validation data.\n",
        "   - The **QCNN** stabilizes slightly lower, around 85-90%, indicating that it may be less capable of capturing complex patterns compared to the hybrid models.\n",
        "\n",
        "3. **Fluctuations**:\n",
        "   - The **Hybrid CNN** and **Hybrid CNN with Multiple Quantum Filters** both exhibit slight fluctuations in accuracy between epochs. This is typical in models that are sensitive to validation data variations, potentially due to smaller validation datasets or model sensitivity.\n",
        "   - The **QCNN** line is relatively stable but does not reach the same level of performance as the hybrid models, showing fewer fluctuations but lower overall accuracy.\n",
        "\n",
        "***Insights***\n",
        "\n",
        "1. **Hybrid Model Superiority**:\n",
        "   - Both hybrid models (with and without multiple quantum filters) outperform the pure QCNN. This suggests that combining quantum and classical layers allows for better feature extraction and learning, likely because classical layers complement the quantum layers' feature extraction.\n",
        "\n",
        "2. **Impact of Multiple Quantum Filters**:\n",
        "   - The Hybrid CNN with Multiple Quantum Filters achieves comparable accuracy to the regular Hybrid CNN but maintains a consistently high performance after the initial epochs. This may suggest that multiple quantum filters help extract a richer set of features, making the model more robust.\n",
        "\n",
        "3. **QCNN Limitations**:\n",
        "   - While the QCNN performs reasonably well, it does not reach the same accuracy levels as the hybrid models. This could indicate that a purely quantum approach may be limited in capturing all the necessary patterns in the data for this task.\n",
        "\n",
        "4. **Potential Overfitting**:\n",
        "   - The Hybrid CNN models achieve near-perfect accuracy in some epochs. If the validation dataset is not representative enough, this could be a sign of overfitting. However, if the dataset is sufficient, this high accuracy indicates the models are highly effective.\n",
        "\n",
        "***Summary***\n",
        "\n",
        "- The **Hybrid CNN with Multiple Quantum Filters** and **Hybrid CNN** models consistently outperform the **QCNN** in terms of validation accuracy.\n",
        "- The **Hybrid CNN with Multiple Quantum Filters** shows slightly more robustness, likely due to the added complexity and feature extraction capability of multiple quantum filters.\n",
        "- The results suggest that hybrid models leveraging both quantum and classical components are more effective for this task than purely quantum models.\n",
        "\n",
        "This plot highlights the advantage of hybrid quantum-classical architectures for certain tasks, demonstrating that they can outperform purely quantum models in terms of both learning speed and accuracy."
      ],
      "metadata": {
        "id": "IzeT3SrL6q7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final conclusion of this project comparing Quantum Convolutional Neural Networks (QCNNs) and Hybrid Convolutional Neural Networks (Hybrid CNNs) in detecting patterns in quantum data can be summarized as follows:\n",
        "\n",
        "# Key Conclusions\n",
        "\n",
        "1. **Hybrid Models Outperform Purely Quantum Models**:\n",
        "   - Throughout the training, the hybrid models (especially the **Hybrid CNN with Multiple Quantum Filters**) consistently achieved higher validation accuracy than the pure QCNN.\n",
        "   - The ability to combine quantum feature extraction with classical processing layers allows the hybrid models to capture and process more complex patterns than the purely quantum QCNN. This suggests that hybrid architectures can leverage the strengths of both quantum and classical processing to improve learning outcomes.\n",
        "\n",
        "2. **Multiple Quantum Filters Add Value**:\n",
        "   - The **Hybrid CNN with Multiple Quantum Filters** performed slightly better and more stably than the regular Hybrid CNN, demonstrating that incorporating multiple quantum filters can enhance feature extraction in quantum data.\n",
        "   - By applying multiple quantum circuits in parallel, the model extracts a richer and more diverse set of features, allowing it to be more robust and potentially more accurate, especially on complex tasks.\n",
        "\n",
        "3. **Efficiency and Learning Speed**:\n",
        "   - The Hybrid CNN models achieved high accuracy within the first few epochs, indicating faster learning compared to the QCNN.\n",
        "   - This efficiency is beneficial in practical applications where quick convergence and high performance are required, especially when training with quantum resources, which can be limited.\n",
        "\n",
        "4. **Implications for Quantum Machine Learning**:\n",
        "   - The results demonstrate that **quantum-classical hybrid models** are highly promising for quantum machine learning, especially in scenarios where pure quantum models may fall short.\n",
        "   - Hybrid models are likely to be a practical choice for many near-term applications in quantum computing, where fully quantum approaches may lack sufficient computational power or complexity to outperform hybrid architectures.\n",
        "\n",
        "5. **Potential for Generalization**:\n",
        "   - The hybrid models' ability to generalize well on validation data without significant overfitting (as indicated by similar training and validation performance) suggests that they are effective for broader applications beyond this specific dataset."
      ],
      "metadata": {
        "id": "HUbwD9R27UrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overall Conclusion\n",
        "\n",
        "This project highlights the strength of **hybrid quantum-classical models** in quantum machine learning. By combining quantum circuits' unique ability to process quantum data with classical neural networks' robust optimization and learning power, hybrid models provide a compelling solution that currently outperforms purely quantum approaches in accuracy, efficiency, and generalization.\n",
        "\n",
        "As quantum computing technology continues to advance, these findings underscore the potential of hybrid architectures to play a central role in practical quantum machine learning applications, particularly as we bridge the gap between classical and quantum processing capabilities."
      ],
      "metadata": {
        "id": "wK8nmS7k7Y7W"
      }
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}